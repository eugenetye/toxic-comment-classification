{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz22iJXiW6kf"
      },
      "outputs": [],
      "source": [
        "# 0. Install Dependencies and Bring in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFuQYSkuVWHL"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prWGA6lCWJi2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FvNEOXfWiy-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join('new', 'train.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JdRPRM9ZpPj"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzq-5TWeZ8yQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJkcJ2eRaVwQ"
      },
      "outputs": [],
      "source": [
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAclnDnCa4_L"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES = 200000     # number of words in the vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th0TtpkhbESL"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khf3y0uJ2xPg"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uByOFztX3reR"
      },
      "outputs": [],
      "source": [
        "vectorized_text = vectorizer(X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m063ibIL4h_6",
        "outputId": "b612626d-8bd7-4bb7-83d8-4bb450cbc00c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
              "array([[  645,    76,     2, ...,     0,     0,     0],\n",
              "       [    1,    54,  2489, ...,     0,     0,     0],\n",
              "       [  425,   441,    70, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [32445,  7392,   383, ...,     0,     0,     0],\n",
              "       [    5,    12,   534, ...,     0,     0,     0],\n",
              "       [    5,     8,   130, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "vectorized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orqoVms04tjl"
      },
      "outputs": [],
      "source": [
        "#MCSHBAP - map, cache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8)   # helps prevent bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdurNNvBCCPm"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y = dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXMY0cTwCSsd"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq9krN8VFAVB"
      },
      "outputs": [],
      "source": [
        "train_generator = train.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5aLJcZLFVXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d655d4d-3838-4676-a675-eac0b6faf6dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  256,    36,    72, ...,     0,     0,     0],\n",
              "        [ 3680,   995,  1288, ...,     0,     0,     0],\n",
              "        [46959,  3513,   171, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    8,    55,    72, ...,     0,     0,     0],\n",
              "        [    8,    19,     6, ...,     0,     0,     0],\n",
              "        [32445,  7392,   383, ...,     0,     0,     0]]),\n",
              " array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwI1sX8zGSyw"
      },
      "outputs": [],
      "source": [
        "# 2. Create Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4MXR2D1GbGS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn6qqqaHGgx0"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Create the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES + 1, 32))\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "\n",
        "# Feature extractor Fully connected layers\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "# Final layer\n",
        "model.add(Dense(6, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfZ4x36sSb-h"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeGwX416TFG3",
        "outputId": "9e087b65-475d-4d00-fbea-af3e33bd1a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,491,686\n",
            "Trainable params: 6,491,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNYBr9-mUJ6a",
        "outputId": "73bca052-5e0a-45a3-aeeb-a7c675a9fdc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6981/6981 [==============================] - 10671s 2s/step - loss: 0.0625 - val_loss: 0.0468\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, epochs = 1, validation_data=val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Make Predictions "
      ],
      "metadata": {
        "id": "MAxaJhjkypx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = vectorizer(\"Fuck you\")"
      ],
      "metadata": {
        "id": "IplNGzx-yubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "qLNHHvbm0Vft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "UE-R0NPG0lSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(model.predict(batch_X) > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "samLOO9uzBvU",
        "outputId": "5f65127c-e473-4f21-c434-8a51ddc29512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuFKK4180GwO",
        "outputId": "d0986ed8-872e-4a0f-f4e2-406bad0b538a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
              "       'identity_hate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(np.expand_dims(input_text, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIUhChi03EM9",
        "outputId": "54c13599-2e89-4737-f1d4-4fc51f4a0625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate Model"
      ],
      "metadata": {
        "id": "UoTlkGFq1nek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ],
      "metadata": {
        "id": "tgKQN0Bi1qaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "W1BE0nu11x25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "\n",
        "  # Unpack the batch\n",
        "  X_true, y_true = batch\n",
        "\n",
        "  # Make a prediction\n",
        "  yhat = model.predict(X_true)\n",
        "\n",
        "  # Flatten the predictions\n",
        "  y_true = y_true.flatten()\n",
        "  yhat = yhat.flatten()\n",
        "\n",
        "  pre.update_state(y_true, yhat)\n",
        "  re.update_state(y_true, yhat)\n",
        "  acc.update_state(y_true, yhat)"
      ],
      "metadata": {
        "id": "Rz2qMk3w2DU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Categorical Accuracy: {acc.result().numpy()}\")"
      ],
      "metadata": {
        "id": "w6x8Lgld3yfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d9627d-e6e5-4695-d43a-20c02df79090"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.779793918132782, Recall: 0.7248427867889404, Categorical Accuracy: 0.4774323105812073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Test and Gradio"
      ],
      "metadata": {
        "id": "fzgV0QAu5ybj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio jinja2"
      ],
      "metadata": {
        "id": "U48oZ5bC557w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "vnJlL1nK6S2o"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicity.h5')"
      ],
      "metadata": {
        "id": "g8HQ7IFs6WKi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('toxicity.h5')"
      ],
      "metadata": {
        "id": "2bgcDPSdEcBj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = vectorizer(\"Hey I freaking hate you!\")"
      ],
      "metadata": {
        "id": "rlIC-3rhEqWo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(np.expand_dims(input_str, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upi5z-XJExNC",
        "outputId": "144bb375-871d-489e-dcad-aeb9b67bba37"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 148ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res > 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbdmOjKlE5nI",
        "outputId": "a77b1ca6-f149-4a8f-ba54-157e589236ee"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False,  True, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment):\n",
        "  vectorized_comment = vectorizer([comment])\n",
        "  results = model.predict(vectorized_comment)\n",
        "\n",
        "  text = ''\n",
        "  for idx, col in enumerate(df.columns[2:]):\n",
        "    text += '{}: {}\\n'.format(col, results[0][idx] > 0.5)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "ENwmxihpFX75"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn = score_comment, inputs = gr.inputs.Textbox(lines = 2, placeholder = 'Comment to score'), outputs = 'text')"
      ],
      "metadata": {
        "id": "jaTzQhgGGj7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "9Ui211hSHA5l",
        "outputId": "8c3fefbb-f3d2-4d70-82b3-16ad40839787"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://175b565a-c061-4c67.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://175b565a-c061-4c67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}